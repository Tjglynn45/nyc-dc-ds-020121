{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA - Analysis of Variance\n",
    "\n",
    "Today, we will be learning ANOVA, a generalized form of comparing means across multiple groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "SWBAT:\n",
    "\n",
    "- Compare and contrast $t$-tests with ANOVA;\n",
    "- Differentiate between \"variance between groups\" and \"variance within groups\";\n",
    "- Calculate ANOVA stats;\n",
    "- Implement ANOVA in Python\n",
    "    - using `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $t$-tests or ANOVA?\n",
    "\n",
    "**ANOVA** or *Analysis Of Variance*  provides a statistical test of whether two or more population means are equal, and therefore generalizes the $t$-test beyond two means.\n",
    "\n",
    "Suppose we want to compare whether multiple groups differ in some measure. For example, we have collected mood data grouped by four types of weather - sunny, raining, overcast, or cloudy, and we want to find out whether there is a difference in mood across different weather. What tests would you use?\n",
    "\n",
    "A natural reaction would be to conduct multiple $t$-tests. However, that comes with many drawbacks. First, you would need $\\frac{n(n-1)}{2}$ t tests, which comes out to 6 tests. More tests means having a higher chance of making a Type I error. In this case, if our original probability of making a Type I error was $5\\%$, it would now grow to $1-(1-0.05)^6 = 26\\%$! By conducting 6 tests and comparing their means to each other, we are running a huge risk of making false positives. This is known as the **multiple comparisons problem**. How then, can we combat this? -- ANOVA!\n",
    "\n",
    "Instead of looking at each individual difference, ANOVA examines the ratio of variance between groups, and variance within groups, to find out whether the ratio is big enough to be statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t$-Test statistics\n",
    "\n",
    "##### One sample\n",
    "$t = \\frac{x\\bar - \\mu}{\\frac{s}{\\sqrt n}}$\n",
    "\n",
    "##### Two sample\n",
    "$$ t = \\frac{\\bar{x_1} - \\bar{x_2}}{\\sqrt{s^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}}$$\n",
    "\n",
    "where $s^2$ is the pooled sample variance:\n",
    "\n",
    "$$ s^2 = \\frac{\\sum_{i=1}^{n_1} \\left(x_i - \\bar{x_1}\\right)^2 + \\sum_{j=1}^{n_2} \\left(x_j - \\bar{x_2}\\right)^2 }{n_1 + n_2 - 2} $$\n",
    "\n",
    "We can also say that a $t$-test is a special case of ANOVA in that we are comparing the means of only two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](img/choosing_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ANOVA - the $F$ test\n",
    "\n",
    "$F = \\frac{s^2_{between}}{s^2_{within}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like $t$ and $z$ tests, we calculate a test statistic, then compare it to a critical value associated with a probability distribution. In this case, that distribution is the [$F$-distribution](https://en.wikipedia.org/wiki/F-distribution).\n",
    "\n",
    "![fdistribution](img/f_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://vassarstats.net/textbook/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "one = np.random.normal(0, 3, 100)\n",
    "two = np.random.normal(1, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"one-way\" just means that there is a single\n",
    "# input variable.\n",
    "\n",
    "stats.f_oneway(one, two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical p_values\n",
    "\n",
    "t = stats.ttest_ind(one, two, equal_var=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The square of the two-sample t-stat = the F-stat\n",
    "t.statistic**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension Check\n",
    "\n",
    "Which test would you run for each these scenarios?\n",
    "\n",
    "1. The average salary per month of an English Premier League player is â‚¬240,000. You would like to test whether players who don't have a dominant foot make more than the rest of the league. There are only 25 players who are considered ambidextrous. \n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "    Check\n",
    "</summary>\n",
    "    - Predictor variable is categorical (dominant foot or not) <br/>\n",
    "    - Outcome variable is quantitative (monthly salary) <br/>\n",
    "    - Two groups compared <br/>\n",
    "    - Therefore: $t$-test\n",
    "        - ONE sample (comparing small ambidextrous sample with population)\n",
    "        - ONE tail (MORE $ or not)\n",
    "</details>\n",
    "\n",
    "2. You would like to test whether there is a difference in arrest rates across neighborhoods with different racial majorities. You have point statistics of mean arrest rates associated with neighborhoods of majority White, Black, Hispanic, and Asian populations.\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        Check\n",
    "    </summary>\n",
    "    ANOVA\n",
    "</details>\n",
    "\n",
    "3. You are interested in testing whether the superstition that black cats are bad luck affects adoption rate. You would like to test whether black-fur shelter cats get adopted at a different rate from cats of other fur colors.\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        Check\n",
    "    </summary>\n",
    "    $t$-test\n",
    "        - TWO samples (black cats and non-black cats)\n",
    "        - TWO tails (greater or lesser rate)\n",
    "</details>\n",
    "\n",
    "4. You are interested in whether car-accident rates in cities where marijuana is legal differs from the general rate of car accidents. Assume you know the standard deviation of car accident rates across all U.S. cities.\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        Check\n",
    "    </summary>\n",
    "    $z$-test\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. *Variance between groups* vs. *variance within groups*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/12/image046.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Between Group Variability\n",
    "\n",
    "Measures how much the means of each group vary from the mean of the overall population\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/12/image0171.png\" width=\"500\">\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within Group Variability\n",
    "\n",
    "Refers to variations caused by differences within individual groups.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the given distributions of three samples below. As the spread (variability) of each sample is increased, their distributions overlap and they become part of a big population.\n",
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/12/image031.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider another distribution of the same three samples but with less variability. Although the means of samples are similar to the samples in the above image, they seem to belong to different populations.\n",
    "\n",
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/12/image033.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will three datasets with similar means have small $F$-statistics? Not necessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three sets of data without much difference in means\n",
    "np.random.seed(42)\n",
    "\n",
    "a = np.random.normal(loc=20, scale=20, size=20)\n",
    "b = np.random.normal(loc=22, scale=20, size=20)\n",
    "c = np.random.normal(loc=19, scale=20, size=20)\n",
    "\n",
    "d = np.random.normal(loc=20, scale=2, size=20)\n",
    "e = np.random.normal(loc=22, scale=2, size=20)\n",
    "f = np.random.normal(loc=19, scale=2, size=20)\n",
    "\n",
    "g = np.random.normal(loc=20, scale=10, size=20)\n",
    "h = np.random.normal(loc=20, scale=10, size=20)\n",
    "i = np.random.normal(loc=23, scale=10, size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.f_oneway(a, b, c))\n",
    "print(stats.f_oneway(d, e, f))\n",
    "print(stats.f_oneway(g, h, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculating ANOVA \n",
    "In this section, we will learn how to calculate ANOVA without using any packages. All we need to calculate is: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachment:Screen%20Shot%202019-06-03%20at%2010.36.09%20AM.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bar{X} = $ Mean of entire dataset\n",
    "\n",
    "\n",
    "$SST$ = Total Sum of Squares is the sum of the squares of the difference between every value and $\\bar X$.\n",
    "\n",
    "- $SS_T$ = $\\sum(X_{ij} - \\bar X)^2$\n",
    "\n",
    "The total sum of squares can be broken down into $SSB$, the sum of squares between, and $SSW$, the sum of squares within.\n",
    "\n",
    "- $SS_T =  SS_B+SS_W$\n",
    "\n",
    "$SSB$ accounts for the variance in the dataset that comes from the differences among the means of each sample.\n",
    "\n",
    "- $SS_B$ = $\\sum(n_i(\\bar X - \\bar{X_i})^2)$\n",
    "\n",
    "$SSW$ accounts for the variance in the dataset that comes from within each sample.\n",
    "\n",
    "- $SS_W$ = $\\sum (n_i - 1) s_i ^ 2$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degrees of Freedom for ANOVA:\n",
    "-  $DF_{between} = k - 1$\n",
    "- $DF_{within} = N - k$\n",
    "- $DF_{total} = N - 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation:\n",
    "- $k$ is the number of groups\n",
    "- $N$ is the total number of observations\n",
    "- $n_i$ is the number of observations in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $MS_B$ = $\\frac{SS_B}{DF_B}$\n",
    "- $MS_W$ = $\\frac{SS_W}{DF_W}$\n",
    "- $F$ = $\\frac{MS_B}{MS_W}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "Like $z$-tests and $t$-tests, we can also perform hypothesis testing with ANOVA. \n",
    "\n",
    "- $H_0$ : $\\mu{_1}$ = $\\mu_2$ = $\\mu_3$ = $\\mu_4$\n",
    "- $H_a$ : $H_0$ is not true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bikeshare_day.csv')\n",
    "df.head()\n",
    "# cnt is the outcome we are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to conduct a little bit of feature engineering \n",
    "df['season_cat'] = df.season.apply(lambda x: 'spring' if x == 1 else \n",
    "                                           (\n",
    "                                            'summer' if x == 2 else (\n",
    "                                                'fall' if x == 3 else 'winter')\n",
    "                                           )\n",
    "                                      )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot\n",
    "# 1 is spring, 2 is summer, 3 is fall, and 4 is winter\n",
    "\n",
    "df.boxplot('cnt', by='season_cat', figsize=(6,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could perform two-sample t-tests for each pair of samples.\n",
    "\n",
    "# subset the dataframe  by season and isolate the dependent variable\n",
    "spring = df[df.season_cat == 'spring'].cnt\n",
    "fall = df[df.season_cat == 'fall'].cnt\n",
    "summer = df[df.season_cat == 'summer'].cnt\n",
    "winter = df[df.season_cat == 'winter'].cnt\n",
    "\n",
    "# We could run independent t-tests for each combination\n",
    "# But that increases the chance of making a type I (False Positive) error\n",
    "# Also, as your groups increase, the number of tests may prove impractical\n",
    "\n",
    "print(stats.ttest_ind(spring, fall, equal_var=False))\n",
    "print(stats.ttest_ind(spring, summer, equal_var=False))\n",
    "print(stats.ttest_ind(spring, winter, equal_var=False ))\n",
    "print(stats.ttest_ind(fall, summer, equal_var=False))\n",
    "print(stats.ttest_ind(fall, winter, equal_var=False))\n",
    "print(stats.ttest_ind(summer, winter, equal_var=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time with ANOVA\n",
    "\n",
    " # 1. Calculate the overall mean.\n",
    "\n",
    "X_bar = df.cnt.mean()\n",
    "print('X_bar: ', X_bar)\n",
    "\n",
    " # 2. Define a variable that contains the total variability\n",
    " # of the dataset\n",
    "\n",
    "MS_T = sum([(x - X_bar)**2 for x in df.cnt])\n",
    "print('MS_T: ', MS_T)\n",
    "\n",
    " # 3. Define a variable that contains the variability of the\n",
    " # dataset that results from the difference of means.\n",
    "\n",
    "MS_B = sum(\n",
    "            [len(df[df.season_cat == season])*\n",
    "             (X_bar \n",
    "             - np.mean(df[df.season_cat == season].cnt))**2 \n",
    "             for season in df.season_cat.unique()\n",
    "            ])\n",
    "print('MS_B: ', MS_B)\n",
    "\n",
    " # 4. Define a variable that contains the variablity of the\n",
    " # dataset that results from the variance of each sample.\n",
    "    \n",
    "MS_W = sum(\n",
    "            [(len(df[df.season_cat == season])-1)\n",
    "             * np.var(df[df.season_cat == season].cnt, ddof=1)\n",
    "             for season in df.season_cat.unique()\n",
    "            ])\n",
    "print('MS_W: ', MS_W)\n",
    "\n",
    " # 5. Sanity Check: Make sure all of the variability of the\n",
    " # dataset is accounted for by the two last answers.\n",
    "\n",
    "print(np.allclose(MS_T, MS_B + MS_W))\n",
    "\n",
    " # 6. Define variables that contain the values of the two\n",
    " # important degrees of freedom.\n",
    "\n",
    "df_B = 4 - 1\n",
    "df_W = len(df) - 4\n",
    "\n",
    " # 7. Define a variable for the variance of weighted\n",
    " # individual group means.\n",
    "\n",
    "MSB = MS_B / df_B\n",
    "print('MSB: ', MSB)\n",
    "\n",
    " # 8. Define a variable for the variance of the weighted\n",
    " # individual group variances.\n",
    "\n",
    "MSW = MS_W/df_W\n",
    "print('MSW: ', MSW)\n",
    "\n",
    " # 9. Define the F-stat.\n",
    "\n",
    "f_stat = MSB / MSW\n",
    "print('F-stat: ', f_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9 # Ensure that the prior calculation matches the output below:\n",
    "\n",
    "f = stats.f_oneway(df['cnt'][df['season_cat'] == 'summer'],\n",
    "                df['cnt'][df['season_cat'] == 'fall'], \n",
    "                df['cnt'][df['season_cat'] == 'winter'],\n",
    "                df['cnt'][df['season_cat'] == 'spring'])\n",
    "\n",
    "np.allclose(f.statistic, f_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. First Glimpse of Statsmodels OLS Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_season = ols('cnt ~ season_cat', data=df).fit()\n",
    "anova_season.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Just because we have rejected the null hypothesis, it doesn't mean we have conclusively shown which group is significantly different from which - remember, the alternative hypothesis says simply that the null hypothesis is not true.\n",
    "\n",
    "We need to conduct post-hoc tests for multiple comparisons to find out which groups are different. The most prominent post-hoc tests are:\n",
    "- LSD (Least significant difference)\n",
    "    - $t\\sqrt \\frac{MSE}{n^2}$\n",
    "- Tukey's HSD \n",
    "    - $q\\sqrt \\frac{MSE}{n}$\n",
    "    \n",
    "https://www.statisticshowto.com/studentized-range-distribution/#qtable\n",
    "    \n",
    "After calculating a value for LSD or HSD, we compare each pair wise mean difference with the LSD or HSD difference. If the pairwise mean difference exceeds the LSD/HSD, then they are significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pairwise_tukeyhsd(df.cnt, df.season_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Way ANOVA:\n",
    "\n",
    "Returning to the example at the very beginning of the lesson, say \n",
    "we found out, using one-way ANOVA, that the season was impactful on the mood of different people. What if the season was to affect different groups of people differently?  Maybe older people were affected more by the seasons than younger people.\n",
    "\n",
    "Moreover, how can we be sure as to which factor(s) is affecting the mood more? Maybe the age group is a more dominant factor responsible for a person's mood than the season.\n",
    "\n",
    "For such cases, when the outcome or dependent variable is affected by two independent variables/factors we use a slightly modified technique called two-way ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Resources\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/\n",
    "    \n",
    "https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/anova/how-to/one-way-anova/before-you-start/overview/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
